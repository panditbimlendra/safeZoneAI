{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e302c983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup and imports\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import (Conv3D, MaxPooling3D, Flatten, Dense, \n",
    "                                    LSTM, TimeDistributed, ConvLSTM2D, Dropout,\n",
    "                                    BatchNormalization, Input, Reshape)\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf8458ec",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;43;01mclass\u001b[39;49;00m\u001b[38;5;250;43m \u001b[39;49m\u001b[34;43;01mConfig\u001b[39;49;00m\u001b[43m:\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Get the current script directory\u001b[39;49;00m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mBASE_DIR\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[34;43m__file__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparent\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Dataset parameters\u001b[39;49;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36mConfig\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mConfig\u001b[39;00m:\n\u001b[32m      5\u001b[39m     \u001b[38;5;66;03m# Get the current script directory\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     BASE_DIR = Path(\u001b[34;43m__file__\u001b[39;49m).parent\n\u001b[32m      8\u001b[39m     \u001b[38;5;66;03m# Dataset parameters\u001b[39;00m\n\u001b[32m      9\u001b[39m     SEQUENCE_LENGTH = \u001b[32m20\u001b[39m\n",
      "\u001b[31mNameError\u001b[39m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "class Config:\n",
    "    # Get the current script directory\n",
    "    BASE_DIR = Path(__file__).parent\n",
    "    \n",
    "    # Dataset parameters\n",
    "    SEQUENCE_LENGTH = 20\n",
    "    IMG_HEIGHT = 224\n",
    "    IMG_WIDTH = 224\n",
    "    CHANNELS = 3\n",
    "    \n",
    "    # Training parameters\n",
    "    EPOCHS = 50\n",
    "    BATCH_SIZE = 8\n",
    "    LEARNING_RATE = 0.0001\n",
    "    VALIDATION_SPLIT = 0.2\n",
    "    TEST_SPLIT = 0.1\n",
    "    \n",
    "    # Paths - using absolute paths\n",
    "    DATASET_DIR = BASE_DIR / \"dataset\"\n",
    "    ACCIDENT_DIR = DATASET_DIR / \"accident\"\n",
    "    NON_ACCIDENT_DIR = DATASET_DIR / \"non_accident\"\n",
    "    MODEL_SAVE_PATH = BASE_DIR / \"models\" / \"accident_detection_model.h5\"\n",
    "    \n",
    "    # Create directories if they don't exist\n",
    "    DATASET_DIR.mkdir(exist_ok=True)\n",
    "    ACCIDENT_DIR.mkdir(exist_ok=True)\n",
    "    NON_ACCIDENT_DIR.mkdir(exist_ok=True)\n",
    "    (BASE_DIR / \"models\").mkdir(exist_ok=True)\n",
    "\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df2a293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing \n",
    "def extract_frames(video_path, max_frames=0):\n",
    "    \"\"\"\n",
    "    Extract frames from video file\n",
    "    \"\"\"\n",
    "    frames = []\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    try:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "                \n",
    "            # Resize and normalize frame\n",
    "            frame = cv2.resize(frame, (config.IMG_WIDTH, config.IMG_HEIGHT))\n",
    "            frame = frame / 255.0\n",
    "            frames.append(frame)\n",
    "            \n",
    "            if 0 < max_frames <= len(frames):\n",
    "                break\n",
    "    finally:\n",
    "        cap.release()\n",
    "    \n",
    "    return np.array(frames)\n",
    "\n",
    "def create_sequences(frames, sequence_length):\n",
    "    \"\"\"\n",
    "    Create sequences of frames from video\n",
    "    \"\"\"\n",
    "    sequences = []\n",
    "    for i in range(len(frames) - sequence_length + 1):\n",
    "        sequence = frames[i:i + sequence_length]\n",
    "        sequences.append(sequence)\n",
    "    return np.array(sequences)\n",
    "\n",
    "def load_dataset():\n",
    "    \"\"\"\n",
    "    Load and preprocess the entire dataset\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    # Load accident videos\n",
    "    for video_file in os.listdir(config.ACCIDENT_DIR):\n",
    "        if video_file.endswith(('.mp4', '.avi', '.mov')):\n",
    "            video_path = os.path.join(config.ACCIDENT_DIR, video_file)\n",
    "            frames = extract_frames(video_path)\n",
    "            sequences = create_sequences(frames, config.SEQUENCE_LENGTH)\n",
    "            X.extend(sequences)\n",
    "            y.extend([1] * len(sequences))  # 1 for accident\n",
    "    \n",
    "    # Load non-accident videos\n",
    "    for video_file in os.listdir(config.NON_ACCIDENT_DIR):\n",
    "        if video_file.endswith(('.mp4', '.avi', '.mov')):\n",
    "            video_path = os.path.join(config.NON_ACCIDENT_DIR, video_file)\n",
    "            frames = extract_frames(video_path)\n",
    "            sequences = create_sequences(frames, config.SEQUENCE_LENGTH)\n",
    "            X.extend(sequences)\n",
    "            y.extend([0] * len(sequences))  # 0 for non-accident\n",
    "    \n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "def prepare_datasets(X, y):\n",
    "    \"\"\"\n",
    "    Split dataset into train, validation and test sets\n",
    "    \"\"\"\n",
    "    # First split into train+val and test\n",
    "    X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "        X, y, test_size=config.TEST_SPLIT, random_state=42, stratify=y)\n",
    "    \n",
    "    # Then split train+val into train and val\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train_val, y_train_val, test_size=config.VALIDATION_SPLIT, \n",
    "        random_state=42, stratify=y_train_val)\n",
    "    \n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model architecture\n",
    "# 3d cnn model \n",
    "def create_3d_cnn_model():\n",
    "    \"\"\"\n",
    "    Create a 3D CNN model for spatiotemporal feature extraction\n",
    "    \"\"\"\n",
    "    model = Sequential([\n",
    "        # First 3D convolution layer\n",
    "        Conv3D(32, (3, 3, 3), activation='relu', \n",
    "               input_shape=(config.SEQUENCE_LENGTH, config.IMG_HEIGHT, \n",
    "                           config.IMG_WIDTH, config.CHANNELS)),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling3D((1, 2, 2)),\n",
    "        Dropout(0.25),\n",
    "        \n",
    "        # Second 3D convolution layer\n",
    "        Conv3D(64, (3, 3, 3), activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling3D((1, 2, 2)),\n",
    "        Dropout(0.25),\n",
    "        \n",
    "        # Third 3D convolution layer\n",
    "        Conv3D(128, (3, 3, 3), activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling3D((1, 2, 2)),\n",
    "        Dropout(0.25),\n",
    "        \n",
    "        # Flatten and dense layers\n",
    "        Flatten(),\n",
    "        Dense(256, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    optimizer = Adam(learning_rate=config.LEARNING_RATE)\n",
    "    model.compile(optimizer=optimizer, \n",
    "                  loss='binary_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c758bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convlstm model \n",
    "def create_convlstm_model():\n",
    "    \"\"\"\n",
    "    Create a ConvLSTM model for better temporal modeling\n",
    "    \"\"\"\n",
    "    model = Sequential([\n",
    "        # First ConvLSTM layer\n",
    "        ConvLSTM2D(32, (3, 3), activation='tanh', recurrent_activation='hard_sigmoid',\n",
    "                   return_sequences=True,\n",
    "                   input_shape=(config.SEQUENCE_LENGTH, config.IMG_HEIGHT, \n",
    "                               config.IMG_WIDTH, config.CHANNELS)),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling3D((1, 2, 2)),\n",
    "        Dropout(0.25),\n",
    "        \n",
    "        # Second ConvLSTM layer\n",
    "        ConvLSTM2D(64, (3, 3), activation='tanh', recurrent_activation='hard_sigmoid',\n",
    "                   return_sequences=True),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling3D((1, 2, 2)),\n",
    "        Dropout(0.25),\n",
    "        \n",
    "        # Third ConvLSTM layer\n",
    "        ConvLSTM2D(128, (3, 3), activation='tanh', recurrent_activation='hard_sigmoid',\n",
    "                   return_sequences=False),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling3D((1, 2, 2)),\n",
    "        Dropout(0.25),\n",
    "        \n",
    "        # Flatten and dense layers\n",
    "        Flatten(),\n",
    "        Dense(256, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    optimizer = Adam(learning_rate=config.LEARNING_RATE)\n",
    "    model.compile(optimizer=optimizer, \n",
    "                  loss='binary_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fa5b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training pipeline\n",
    "def train_model():\n",
    "    # Load and prepare dataset\n",
    "    print(\"Loading dataset...\")\n",
    "    X, y = load_dataset()\n",
    "    X_train, X_val, X_test, y_train, y_val, y_test = prepare_datasets(X, y)\n",
    "    \n",
    "    print(f\"Training samples: {len(X_train)}\")\n",
    "    print(f\"Validation samples: {len(X_val)}\")\n",
    "    print(f\"Test samples: {len(X_test)}\")\n",
    "    \n",
    "    # Create model (choose one)\n",
    "    print(\"Creating model...\")\n",
    "    model = create_3d_cnn_model()  # or create_convlstm_model()\n",
    "    model.summary()\n",
    "    \n",
    "    # Callbacks\n",
    "    callbacks = [\n",
    "        ModelCheckpoint(\n",
    "            config.MODEL_SAVE_PATH,\n",
    "            monitor='val_accuracy',\n",
    "            save_best_only=True,\n",
    "            mode='max',\n",
    "            verbose=1\n",
    "        ),\n",
    "        EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=10,\n",
    "            restore_best_weights=True\n",
    "        ),\n",
    "        ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,\n",
    "            patience=5,\n",
    "            min_lr=1e-6\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    # Train model\n",
    "    print(\"Training model...\")\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        batch_size=config.BATCH_SIZE,\n",
    "        epochs=config.EPOCHS,\n",
    "        validation_data=(X_val, y_val),\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    print(\"Evaluating on test set...\")\n",
    "    test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(f\"Test Accuracy: {test_acc*100:.2f}%\")\n",
    "    \n",
    "    # Save training history\n",
    "    pd.DataFrame(history.history).to_csv(\"training_history.csv\", index=False)\n",
    "    \n",
    "    return model, history\n",
    "\n",
    "def plot_training_history(history):\n",
    "    \"\"\"\n",
    "    Plot training and validation accuracy and loss\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    # Plot accuracy\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot loss\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('training_history.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914a5d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'dataset\\\\accident'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m os.makedirs(os.path.dirname(config.MODEL_SAVE_PATH), exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m trained_model, training_history = \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Plot training history\u001b[39;00m\n\u001b[32m      9\u001b[39m plot_training_history(training_history)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtrain_model\u001b[39m():\n\u001b[32m      2\u001b[39m     \u001b[38;5;66;03m# Load and prepare dataset\u001b[39;00m\n\u001b[32m      3\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mLoading dataset...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     X, y = \u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m     X_train, X_val, X_test, y_train, y_val, y_test = prepare_datasets(X, y)\n\u001b[32m      7\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTraining samples: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(X_train)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 44\u001b[39m, in \u001b[36mload_dataset\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     41\u001b[39m y = []\n\u001b[32m     43\u001b[39m \u001b[38;5;66;03m# Load accident videos\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m video_file \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mACCIDENT_DIR\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m     45\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m video_file.endswith((\u001b[33m'\u001b[39m\u001b[33m.mp4\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m.avi\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m.mov\u001b[39m\u001b[33m'\u001b[39m)):\n\u001b[32m     46\u001b[39m         video_path = os.path.join(config.ACCIDENT_DIR, video_file)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [WinError 3] The system cannot find the path specified: 'dataset\\\\accident'"
     ]
    }
   ],
   "source": [
    "# main exection\n",
    "if __name__ == \"__main__\":\n",
    "    # Create necessary directories\n",
    "    os.makedirs(os.path.dirname(config.MODEL_SAVE_PATH), exist_ok=True)\n",
    "    \n",
    "    # Train the model\n",
    "    trained_model, training_history = train_model()\n",
    "    \n",
    "    # Plot training history\n",
    "    plot_training_history(training_history)\n",
    "    \n",
    "    # Save the final model\n",
    "    trained_model.save(config.MODEL_SAVE_PATH)\n",
    "    print(f\"Model saved to {config.MODEL_SAVE_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327fc03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data augmentation \n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def create_augmentation_generator():\n",
    "    \"\"\"\n",
    "    Create data generator with augmentation\n",
    "    \"\"\"\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=10,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        zoom_range=0.1,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "    return datagen\n",
    "\n",
    "def augmented_fit(model, X_train, y_train, X_val, y_val):\n",
    "    \"\"\"\n",
    "    Train model with augmented data\n",
    "    \"\"\"\n",
    "    datagen = create_augmentation_generator()\n",
    "    \n",
    "    # Create sequence generator\n",
    "    def sequence_generator(X, y, batch_size):\n",
    "        while True:\n",
    "            for i in range(0, len(X), batch_size):\n",
    "                batch_X = X[i:i + batch_size]\n",
    "                batch_y = y[i:i + batch_size]\n",
    "                \n",
    "                # Apply augmentation to each frame in each sequence\n",
    "                augmented_batch = []\n",
    "                for sequence in batch_X:\n",
    "                    augmented_sequence = []\n",
    "                    for frame in sequence:\n",
    "                        # Expand dims to (1, h, w, c) for augmentation\n",
    "                        augmented_frame = datagen.random_transform(frame)\n",
    "                        augmented_sequence.append(augmented_frame)\n",
    "                    augmented_batch.append(augmented_sequence)\n",
    "                \n",
    "                yield np.array(augmented_batch), batch_y\n",
    "    \n",
    "    # Calculate steps per epoch\n",
    "    steps_per_epoch = len(X_train) // config.BATCH_SIZE\n",
    "    \n",
    "    # Train with generator\n",
    "    history = model.fit(\n",
    "        sequence_generator(X_train, y_train, config.BATCH_SIZE),\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        epochs=config.EPOCHS,\n",
    "        validation_data=(X_val, y_val),\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c262008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optical flow features \n",
    "def compute_optical_flow(prev_frame, next_frame):\n",
    "    \"\"\"\n",
    "    Compute dense optical flow between two frames\n",
    "    \"\"\"\n",
    "    prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "    next_gray = cv2.cvtColor(next_frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    flow = cv2.calcOpticalFlowFarneback(\n",
    "        prev_gray, next_gray, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "    \n",
    "    # Convert flow to RGB representation\n",
    "    hsv = np.zeros((config.IMG_HEIGHT, config.IMG_WIDTH, 3), dtype=np.float32)\n",
    "    hsv[..., 1] = 1.0\n",
    "    \n",
    "    mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "    hsv[..., 0] = ang * (180 / np.pi / 2)\n",
    "    hsv[..., 2] = cv2.normalize(mag, None, 0, 1, cv2.NORM_MINMAX)\n",
    "    \n",
    "    flow_rgb = cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB)\n",
    "    return flow_rgb\n",
    "\n",
    "def extract_optical_flow_sequences(frames, sequence_length):\n",
    "    \"\"\"\n",
    "    Create sequences with optical flow features\n",
    "    \"\"\"\n",
    "    sequences = []\n",
    "    for i in range(len(frames) - sequence_length):\n",
    "        sequence = []\n",
    "        for j in range(i, i + sequence_length - 1):\n",
    "            flow = compute_optical_flow(frames[j], frames[j+1])\n",
    "            sequence.append(flow)\n",
    "        sequences.append(sequence)\n",
    "    return np.array(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b655bfd6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (PyTorch)",
   "language": "python",
   "name": "torch-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
