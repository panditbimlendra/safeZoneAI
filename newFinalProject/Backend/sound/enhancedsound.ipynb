{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b9fe8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# ENHANCED ACCURATE ABNORMAL SOUND DETECTION SYSTEM\n",
    "# ============================================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "import scipy.io.wavfile as wavf\n",
    "from scipy import signal, stats\n",
    "from scipy.signal import butter, filtfilt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ============================================================================\n",
    "# 1. ENHANCED FEATURE EXTRACTION\n",
    "# ============================================================================\n",
    "\n",
    "class AdvancedAudioFeatures:\n",
    "    \"\"\"Extract advanced acoustic features for better accuracy\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def extract_all_features(audio, sr=16000):\n",
    "        \"\"\"Extract comprehensive feature set\"\"\"\n",
    "        features = {}\n",
    "        \n",
    "        # ========== TIME DOMAIN FEATURES ==========\n",
    "        # 1. Energy features\n",
    "        rms = librosa.feature.rms(y=audio)[0]\n",
    "        features['max_rms'] = np.max(rms)\n",
    "        features['mean_rms'] = np.mean(rms)\n",
    "        features['rms_std'] = np.std(rms)\n",
    "        features['rms_skew'] = stats.skew(rms)\n",
    "        features['rms_kurtosis'] = stats.kurtosis(rms)\n",
    "        \n",
    "        # 2. Zero-crossing rate\n",
    "        zcr = librosa.feature.zero_crossing_rate(y=audio)[0]\n",
    "        features['max_zcr'] = np.max(zcr)\n",
    "        features['mean_zcr'] = np.mean(zcr)\n",
    "        features['zcr_std'] = np.std(zcr)\n",
    "        \n",
    "        # 3. Amplitude statistics\n",
    "        features['amplitude_max'] = np.max(np.abs(audio))\n",
    "        features['amplitude_mean'] = np.mean(np.abs(audio))\n",
    "        features['amplitude_std'] = np.std(audio)\n",
    "        features['amplitude_skew'] = stats.skew(audio)\n",
    "        features['amplitude_kurtosis'] = stats.kurtosis(audio)\n",
    "        \n",
    "        # 4. Temporal features\n",
    "        envelope = np.abs(signal.hilbert(audio))\n",
    "        features['attack_time'] = np.argmax(envelope) / sr\n",
    "        features['decay_time'] = len(audio) / sr - features['attack_time']\n",
    "        features['crest_factor'] = np.max(np.abs(audio)) / (np.sqrt(np.mean(audio**2)) + 1e-8)\n",
    "        features['dynamic_range'] = 20 * np.log10(np.max(np.abs(audio)) / (np.min(np.abs(audio[np.nonzero(audio)])) + 1e-8))\n",
    "        \n",
    "        # ========== FREQUENCY DOMAIN FEATURES ==========\n",
    "        # 5. Spectral features\n",
    "        spectral_centroid = librosa.feature.spectral_centroid(y=audio, sr=sr)[0]\n",
    "        spectral_bandwidth = librosa.feature.spectral_bandwidth(y=audio, sr=sr)[0]\n",
    "        spectral_rolloff = librosa.feature.spectral_rolloff(y=audio, sr=sr)[0]\n",
    "        spectral_contrast = librosa.feature.spectral_contrast(y=audio, sr=sr)\n",
    "        \n",
    "        features['centroid_mean'] = np.mean(spectral_centroid)\n",
    "        features['centroid_std'] = np.std(spectral_centroid)\n",
    "        features['bandwidth_mean'] = np.mean(spectral_bandwidth)\n",
    "        features['rolloff_mean'] = np.mean(spectral_rolloff)\n",
    "        features['spectral_contrast_mean'] = np.mean(spectral_contrast)\n",
    "        \n",
    "        # 6. Spectral flux (change in spectrum)\n",
    "        spec = np.abs(librosa.stft(audio))\n",
    "        spectral_flux = np.sqrt(np.sum(np.diff(spec, axis=1)**2, axis=0))\n",
    "        features['spectral_flux_max'] = np.max(spectral_flux)\n",
    "        features['spectral_flux_mean'] = np.mean(spectral_flux)\n",
    "        \n",
    "        # 7. Spectral flatness (noise vs tone)\n",
    "        spectral_flatness = librosa.feature.spectral_flatness(y=audio)[0]\n",
    "        features['flatness_mean'] = np.mean(spectral_flatness)\n",
    "        features['flatness_std'] = np.std(spectral_flatness)\n",
    "        \n",
    "        # ========== MFCC & CEPSTRAL FEATURES ==========\n",
    "        # 8. Enhanced MFCC features\n",
    "        mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=20)\n",
    "        for i in range(13):  # First 13 MFCCs are most important\n",
    "            features[f'mfcc_{i}_mean'] = np.mean(mfccs[i])\n",
    "            features[f'mfcc_{i}_std'] = np.std(mfccs[i])\n",
    "        \n",
    "        # 9. MFCC deltas (temporal changes)\n",
    "        mfcc_delta = librosa.feature.delta(mfccs)\n",
    "        features['mfcc_delta_mean'] = np.mean(mfcc_delta)\n",
    "        features['mfcc_delta_std'] = np.std(mfcc_delta)\n",
    "        \n",
    "        # 10. Chroma features (harmonic content)\n",
    "        chroma = librosa.feature.chroma_stft(y=audio, sr=sr)\n",
    "        features['chroma_mean'] = np.mean(chroma)\n",
    "        features['chroma_std'] = np.std(chroma)\n",
    "        \n",
    "        # ========== SPECIALIZED ABNORMAL SOUND FEATURES ==========\n",
    "        # 11. Impulse detection\n",
    "        impulse_ratio = np.sum(np.abs(audio) > 3 * np.std(audio)) / len(audio)\n",
    "        features['impulse_ratio'] = impulse_ratio\n",
    "        \n",
    "        # 12. Silence ratio\n",
    "        silence_threshold = 0.01 * np.max(np.abs(audio))\n",
    "        silence_ratio = np.sum(np.abs(audio) < silence_threshold) / len(audio)\n",
    "        features['silence_ratio'] = silence_ratio\n",
    "        \n",
    "        # 13. Peak frequency detection\n",
    "        fft = np.abs(np.fft.rfft(audio))\n",
    "        freqs = np.fft.rfftfreq(len(audio), 1/sr)\n",
    "        peak_freq = freqs[np.argmax(fft)]\n",
    "        features['peak_frequency'] = peak_freq\n",
    "        \n",
    "        # 14. Harmonic-to-noise ratio\n",
    "        harmonic = librosa.effects.harmonic(audio)\n",
    "        percussive = librosa.effects.percussive(audio)\n",
    "        hnr = np.mean(harmonic**2) / (np.mean(percussive**2) + 1e-8)\n",
    "        features['harmonic_noise_ratio'] = hnr\n",
    "        \n",
    "        return features\n",
    "    \n",
    "    @staticmethod\n",
    "    def extract_abnormal_specific_features(audio, sr):\n",
    "        \"\"\"Features specifically tuned for abnormal sounds\"\"\"\n",
    "        features = {}\n",
    "        \n",
    "        # Gunshot/Explosion detection\n",
    "        # 1. Short-term energy rise\n",
    "        frame_length = 256\n",
    "        hop_length = 128\n",
    "        energy = librosa.feature.rms(y=audio, frame_length=frame_length, hop_length=hop_length)[0]\n",
    "        energy_gradient = np.gradient(energy)\n",
    "        features['energy_rise_max'] = np.max(energy_gradient[energy_gradient > 0])\n",
    "        \n",
    "        # 2. Transient detection\n",
    "        onset_env = librosa.onset.onset_strength(y=audio, sr=sr)\n",
    "        features['onset_strength_max'] = np.max(onset_env)\n",
    "        features['onset_strength_mean'] = np.mean(onset_env)\n",
    "        \n",
    "        # 3. Frequency spread\n",
    "        spectrogram = np.abs(librosa.stft(audio))\n",
    "        freq_variance = np.var(spectrogram, axis=0)\n",
    "        features['freq_variance_max'] = np.max(freq_variance)\n",
    "        \n",
    "        # 4. Temporal centroid\n",
    "        temporal_centroid = np.sum(np.arange(len(audio)) * np.abs(audio)) / np.sum(np.abs(audio))\n",
    "        features['temporal_centroid'] = temporal_centroid / sr\n",
    "        \n",
    "        return features\n",
    "\n",
    "# ============================================================================\n",
    "# 2. MACHINE LEARNING MODEL WITH ENSEMBLE\n",
    "# ============================================================================\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import joblib\n",
    "\n",
    "class EnhancedAbnormalSoundDetector:\n",
    "    \"\"\"Advanced detector with ensemble learning\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.scaler = StandardScaler()\n",
    "        self.models = {}\n",
    "        self.feature_extractor = AdvancedAudioFeatures()\n",
    "        self.is_trained = False\n",
    "        \n",
    "    def extract_features_for_training(self, audio_paths, labels):\n",
    "        \"\"\"Extract features for multiple audio files\"\"\"\n",
    "        features_list = []\n",
    "        labels_list = []\n",
    "        \n",
    "        print(\"Extracting advanced features...\")\n",
    "        for i, (path, label) in enumerate(zip(audio_paths, labels)):\n",
    "            if i % 10 == 0:\n",
    "                print(f\"  Processed {i}/{len(audio_paths)} files\")\n",
    "            \n",
    "            try:\n",
    "                audio, sr = librosa.load(path, sr=16000, duration=2.0)\n",
    "                \n",
    "                # Extract standard features\n",
    "                features = self.feature_extractor.extract_all_features(audio, sr)\n",
    "                \n",
    "                # Extract abnormal-specific features\n",
    "                abnormal_features = self.feature_extractor.extract_abnormal_specific_features(audio, sr)\n",
    "                features.update(abnormal_features)\n",
    "                \n",
    "                features_list.append(list(features.values()))\n",
    "                labels_list.append(label)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"  Skipping {path}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        return np.array(features_list), np.array(labels_list)\n",
    "    \n",
    "    def train_ensemble(self, X, y):\n",
    "        \"\"\"Train ensemble of models for better accuracy\"\"\"\n",
    "        print(\"\\nTraining ensemble of models...\")\n",
    "        \n",
    "        # Split data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=42, stratify=y\n",
    "        )\n",
    "        \n",
    "        # Normalize features\n",
    "        X_train_scaled = self.scaler.fit_transform(X_train)\n",
    "        X_test_scaled = self.scaler.transform(X_test)\n",
    "        \n",
    "        # 1. Random Forest\n",
    "        print(\"  1. Training Random Forest...\")\n",
    "        rf = RandomForestClassifier(\n",
    "            n_estimators=200,\n",
    "            max_depth=20,\n",
    "            min_samples_split=5,\n",
    "            min_samples_leaf=2,\n",
    "            class_weight='balanced',\n",
    "            n_jobs=-1,\n",
    "            random_state=42\n",
    "        )\n",
    "        rf.fit(X_train_scaled, y_train)\n",
    "        self.models['rf'] = rf\n",
    "        rf_score = rf.score(X_test_scaled, y_test)\n",
    "        print(f\"    Accuracy: {rf_score:.4f}\")\n",
    "        \n",
    "        # 2. Gradient Boosting\n",
    "        print(\"  2. Training Gradient Boosting...\")\n",
    "        gb = GradientBoostingClassifier(\n",
    "            n_estimators=100,\n",
    "            learning_rate=0.1,\n",
    "            max_depth=5,\n",
    "            random_state=42\n",
    "        )\n",
    "        gb.fit(X_train_scaled, y_train)\n",
    "        self.models['gb'] = gb\n",
    "        gb_score = gb.score(X_test_scaled, y_test)\n",
    "        print(f\"    Accuracy: {gb_score:.4f}\")\n",
    "        \n",
    "        # 3. SVM with RBF kernel\n",
    "        print(\"  3. Training SVM...\")\n",
    "        svm = SVC(\n",
    "            C=10,\n",
    "            kernel='rbf',\n",
    "            gamma='scale',\n",
    "            probability=True,\n",
    "            class_weight='balanced',\n",
    "            random_state=42\n",
    "        )\n",
    "        svm.fit(X_train_scaled, y_train)\n",
    "        self.models['svm'] = svm\n",
    "        svm_score = svm.score(X_test_scaled, y_test)\n",
    "        print(f\"    Accuracy: {svm_score:.4f}\")\n",
    "        \n",
    "        # 4. Neural Network\n",
    "        print(\"  4. Training Neural Network...\")\n",
    "        nn = MLPClassifier(\n",
    "            hidden_layer_sizes=(100, 50),\n",
    "            activation='relu',\n",
    "            alpha=0.01,\n",
    "            learning_rate_init=0.001,\n",
    "            max_iter=500,\n",
    "            random_state=42\n",
    "        )\n",
    "        nn.fit(X_train_scaled, y_train)\n",
    "        self.models['nn'] = nn\n",
    "        nn_score = nn.score(X_test_scaled, y_test)\n",
    "        print(f\"    Accuracy: {nn_score:.4f}\")\n",
    "        \n",
    "        # 5. Ensemble voting\n",
    "        print(\"  5. Creating ensemble voting classifier...\")\n",
    "        estimators = [\n",
    "            ('rf', rf),\n",
    "            ('gb', gb),\n",
    "            ('svm', svm),\n",
    "            ('nn', nn)\n",
    "        ]\n",
    "        self.models['ensemble'] = VotingClassifier(\n",
    "            estimators=estimators,\n",
    "            voting='soft',\n",
    "            weights=[1.2, 1.0, 1.1, 0.9]  # Weight RF more heavily\n",
    "        )\n",
    "        self.models['ensemble'].fit(X_train_scaled, y_train)\n",
    "        ensemble_score = self.models['ensemble'].score(X_test_scaled, y_test)\n",
    "        print(f\"    Ensemble Accuracy: {ensemble_score:.4f}\")\n",
    "        \n",
    "        # Evaluate\n",
    "        y_pred = self.models['ensemble'].predict(X_test_scaled)\n",
    "        print(f\"\\nðŸ“Š ENSEMBLE PERFORMANCE:\")\n",
    "        print(f\"  Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "        print(\"\\nClassification Report:\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        \n",
    "        self.is_trained = True\n",
    "        return ensemble_score\n",
    "    \n",
    "    def predict(self, audio_path):\n",
    "        \"\"\"Predict using ensemble model\"\"\"\n",
    "        if not self.is_trained:\n",
    "            print(\"âš ï¸ Model not trained. Loading pre-trained model...\")\n",
    "            if not self.load_model():\n",
    "                print(\"âŒ No model available. Please train first.\")\n",
    "                return None\n",
    "        \n",
    "        try:\n",
    "            # Load and extract features\n",
    "            audio, sr = librosa.load(audio_path, sr=16000, duration=2.0)\n",
    "            \n",
    "            # Extract features\n",
    "            features = self.feature_extractor.extract_all_features(audio, sr)\n",
    "            abnormal_features = self.feature_extractor.extract_abnormal_specific_features(audio, sr)\n",
    "            features.update(abnormal_features)\n",
    "            \n",
    "            # Prepare for prediction\n",
    "            X = np.array(list(features.values())).reshape(1, -1)\n",
    "            X_scaled = self.scaler.transform(X)\n",
    "            \n",
    "            # Get predictions from all models\n",
    "            predictions = {}\n",
    "            probabilities = {}\n",
    "            \n",
    "            for name, model in self.models.items():\n",
    "                if name != 'ensemble':\n",
    "                    prob = model.predict_proba(X_scaled)[0]\n",
    "                    pred = model.predict(X_scaled)[0]\n",
    "                    predictions[name] = pred\n",
    "                    probabilities[name] = prob\n",
    "            \n",
    "            # Ensemble prediction\n",
    "            ensemble_pred = self.models['ensemble'].predict(X_scaled)[0]\n",
    "            ensemble_prob = self.models['ensemble'].predict_proba(X_scaled)[0]\n",
    "            \n",
    "            # Get confidence scores\n",
    "            confidence = np.max(ensemble_prob)\n",
    "            \n",
    "            # Determine if abnormal\n",
    "            is_abnormal = ensemble_pred == 1  # Assuming 1 is abnormal class\n",
    "            \n",
    "            # Get detailed probability breakdown\n",
    "            class_names = ['Normal', 'Abnormal', 'Speech', 'Background']\n",
    "            if len(ensemble_prob) > len(class_names):\n",
    "                class_names.extend([f'Class_{i}' for i in range(len(ensemble_prob) - len(class_names))])\n",
    "            \n",
    "            return {\n",
    "                'is_abnormal': bool(is_abnormal),\n",
    "                'predicted_class': int(ensemble_pred),\n",
    "                'confidence': float(confidence),\n",
    "                'class_probabilities': dict(zip(class_names[:len(ensemble_prob)], ensemble_prob)),\n",
    "                'model_predictions': predictions,\n",
    "                'features': features\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Prediction error: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def save_model(self, filename='enhanced_sound_detector.pkl'):\n",
    "        \"\"\"Save trained model\"\"\"\n",
    "        save_data = {\n",
    "            'models': self.models,\n",
    "            'scaler': self.scaler,\n",
    "            'is_trained': self.is_trained\n",
    "        }\n",
    "        joblib.dump(save_data, filename)\n",
    "        print(f\"âœ… Model saved to {filename}\")\n",
    "    \n",
    "    def load_model(self, filename='enhanced_sound_detector.pkl'):\n",
    "        \"\"\"Load trained model\"\"\"\n",
    "        try:\n",
    "            save_data = joblib.load(filename)\n",
    "            self.models = save_data['models']\n",
    "            self.scaler = save_data['scaler']\n",
    "            self.is_trained = save_data['is_trained']\n",
    "            print(f\"âœ… Model loaded from {filename}\")\n",
    "            return True\n",
    "        except:\n",
    "            print(f\"âŒ Could not load model from {filename}\")\n",
    "            return False\n",
    "\n",
    "# ============================================================================\n",
    "# 3. REAL-TIME DETECTION WITH THRESHOLD OPTIMIZATION\n",
    "# ============================================================================\n",
    "\n",
    "class RealTimeAbnormalDetector:\n",
    "    \"\"\"Real-time detection with adaptive thresholds\"\"\"\n",
    "    \n",
    "    def __init__(self, sr=16000, window_size=1.0, hop_size=0.5):\n",
    "        self.sr = sr\n",
    "        self.window_size = int(window_size * sr)\n",
    "        self.hop_size = int(hop_size * sr)\n",
    "        self.buffer = np.array([])\n",
    "        \n",
    "        # Adaptive thresholds (initialize with defaults)\n",
    "        self.thresholds = {\n",
    "            'rms': 0.25,\n",
    "            'zcr': 0.35,\n",
    "            'centroid': 3000,\n",
    "            'crest': 8.0,\n",
    "            'spectral_flux': 5.0\n",
    "        }\n",
    "        \n",
    "        # History for adaptive thresholds\n",
    "        self.history = {\n",
    "            'rms': [],\n",
    "            'zcr': [],\n",
    "            'centroid': [],\n",
    "            'crest': []\n",
    "        }\n",
    "        \n",
    "        # Load pre-trained detector\n",
    "        self.detector = EnhancedAbnormalSoundDetector()\n",
    "        if not self.detector.load_model():\n",
    "            print(\"âš ï¸ No pre-trained model found. Using rule-based detection.\")\n",
    "    \n",
    "    def update_thresholds(self, features):\n",
    "        \"\"\"Adapt thresholds based on recent history\"\"\"\n",
    "        for key in self.history.keys():\n",
    "            if key in features:\n",
    "                self.history[key].append(features[key])\n",
    "                if len(self.history[key]) > 100:  # Keep last 100 values\n",
    "                    self.history[key].pop(0)\n",
    "                \n",
    "                # Update threshold as mean + 2*std of recent history\n",
    "                if len(self.history[key]) > 10:\n",
    "                    mean_val = np.mean(self.history[key])\n",
    "                    std_val = np.std(self.history[key])\n",
    "                    self.thresholds[key] = mean_val + 2 * std_val\n",
    "    \n",
    "    def detect_in_buffer(self, audio_chunk):\n",
    "        \"\"\"Detect abnormal sounds in audio chunk\"\"\"\n",
    "        # Extract features\n",
    "        features = AdvancedAudioFeatures().extract_all_features(audio_chunk, self.sr)\n",
    "        \n",
    "        # Update adaptive thresholds\n",
    "        self.update_thresholds(features)\n",
    "        \n",
    "        # Rule-based detection with adaptive thresholds\n",
    "        alerts = []\n",
    "        \n",
    "        if features['max_rms'] > self.thresholds['rms']:\n",
    "            alerts.append(f\"Loud (RMS: {features['max_rms']:.3f} > {self.thresholds['rms']:.3f})\")\n",
    "        \n",
    "        if features['crest_factor'] > self.thresholds['crest']:\n",
    "            alerts.append(f\"Sharp (Crest: {features['crest_factor']:.1f} > {self.thresholds['crest']:.1f})\")\n",
    "        \n",
    "        if features['max_zcr'] > self.thresholds['zcr']:\n",
    "            alerts.append(f\"Abrupt (ZCR: {features['max_zcr']:.3f} > {self.thresholds['zcr']:.3f})\")\n",
    "        \n",
    "        if features['centroid_mean'] > self.thresholds['centroid']:\n",
    "            alerts.append(f\"High freq ({features['centroid_mean']:.0f}Hz > {self.thresholds['centroid']:.0f}Hz)\")\n",
    "        \n",
    "        # Use ML model if available\n",
    "        ml_result = None\n",
    "        if self.detector.is_trained:\n",
    "            # Temporary save chunk and predict\n",
    "            import tempfile\n",
    "            with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as tmp:\n",
    "                import soundfile as sf\n",
    "                sf.write(tmp.name, audio_chunk, self.sr)\n",
    "                ml_result = self.detector.predict(tmp.name)\n",
    "                os.unlink(tmp.name)\n",
    "        \n",
    "        return {\n",
    "            'is_abnormal': len(alerts) > 0,\n",
    "            'alerts': alerts,\n",
    "            'features': features,\n",
    "            'ml_result': ml_result,\n",
    "            'thresholds': self.thresholds.copy()\n",
    "        }\n",
    "    \n",
    "    def process_stream(self, audio_stream, duration=10):\n",
    "        \"\"\"Process audio stream in real-time\"\"\"\n",
    "        import time\n",
    "        \n",
    "        print(f\"ðŸŽ¤ Listening for {duration} seconds...\")\n",
    "        print(\"Press Ctrl+C to stop\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        abnormal_count = 0\n",
    "        total_chunks = 0\n",
    "        \n",
    "        try:\n",
    "            while time.time() - start_time < duration:\n",
    "                # Get audio chunk (simulated - replace with actual stream)\n",
    "                if len(self.buffer) < self.window_size:\n",
    "                    # Simulate getting more audio\n",
    "                    chunk = np.random.randn(self.hop_size) * 0.1\n",
    "                    self.buffer = np.concatenate([self.buffer, chunk])\n",
    "                \n",
    "                if len(self.buffer) >= self.window_size:\n",
    "                    # Process window\n",
    "                    window = self.buffer[:self.window_size]\n",
    "                    result = self.detect_in_buffer(window)\n",
    "                    \n",
    "                    total_chunks += 1\n",
    "                    \n",
    "                    if result['is_abnormal']:\n",
    "                        abnormal_count += 1\n",
    "                        current_time = time.time() - start_time\n",
    "                        print(f\"\\n[{current_time:.1f}s] ðŸš¨ ABNORMAL SOUND DETECTED!\")\n",
    "                        for alert in result['alerts'][:2]:  # Show first 2 alerts\n",
    "                            print(f\"   â€¢ {alert}\")\n",
    "                        \n",
    "                        if result['ml_result']:\n",
    "                            print(f\"   ML Confidence: {result['ml_result']['confidence']:.1%}\")\n",
    "                    \n",
    "                    # Slide window\n",
    "                    self.buffer = self.buffer[self.hop_size:]\n",
    "                \n",
    "                time.sleep(0.1)  # Simulate real-time\n",
    "                \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\n\\nStopped by user\")\n",
    "        \n",
    "        print(f\"\\nðŸ“Š Summary: {abnormal_count}/{total_chunks} abnormal chunks detected\")\n",
    "        return abnormal_count\n",
    "\n",
    "# ============================================================================\n",
    "# 4. ADVANCED VISUALIZATION AND ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "def plot_detailed_analysis(audio_path, result=None):\n",
    "    \"\"\"Create comprehensive visualization\"\"\"\n",
    "    audio, sr = librosa.load(audio_path, sr=16000, duration=4.0)\n",
    "    \n",
    "    # Extract features\n",
    "    features = AdvancedAudioFeatures().extract_all_features(audio, sr)\n",
    "    \n",
    "    fig = plt.figure(figsize=(18, 12))\n",
    "    \n",
    "    # 1. Waveform with abnormalities highlighted\n",
    "    ax1 = plt.subplot(3, 3, 1)\n",
    "    time = np.linspace(0, len(audio)/sr, len(audio))\n",
    "    ax1.plot(time, audio, 'b-', alpha=0.7, linewidth=0.5)\n",
    "    \n",
    "    # Highlight potential abnormalities\n",
    "    rms = librosa.feature.rms(y=audio)[0]\n",
    "    rms_threshold = 0.25\n",
    "    abnormal_regions = rms > rms_threshold\n",
    "    if np.any(abnormal_regions):\n",
    "        frames = np.where(abnormal_regions)[0]\n",
    "        t_frames = librosa.frames_to_time(frames, sr=sr)\n",
    "        for t in t_frames:\n",
    "            ax1.axvspan(t-0.1, t+0.1, alpha=0.3, color='red')\n",
    "    \n",
    "    ax1.set_title(\"Waveform with Abnormal Regions\", fontweight='bold')\n",
    "    ax1.set_xlabel(\"Time (s)\")\n",
    "    ax1.set_ylabel(\"Amplitude\")\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. Spectrogram with annotations\n",
    "    ax2 = plt.subplot(3, 3, 2)\n",
    "    D = librosa.amplitude_to_db(np.abs(librosa.stft(audio)), ref=np.max)\n",
    "    librosa.display.specshow(D, y_axis='log', x_axis='time', sr=sr, ax=ax2, cmap='hot')\n",
    "    ax2.set_title(\"Spectrogram\", fontweight='bold')\n",
    "    \n",
    "    # 3. Feature radar chart\n",
    "    ax3 = plt.subplot(3, 3, 3, projection='polar')\n",
    "    key_features = ['Loudness', 'Sharpness', 'Abruptness', 'High Freq', 'Impulsiveness']\n",
    "    feature_values = [\n",
    "        min(features['max_rms'] * 3, 1.0),\n",
    "        min(features['crest_factor'] / 15, 1.0),\n",
    "        min(features['max_zcr'] * 2, 1.0),\n",
    "        min(features['centroid_mean'] / 5000, 1.0),\n",
    "        min(features['impulse_ratio'] * 10, 1.0)\n",
    "    ]\n",
    "    \n",
    "    angles = np.linspace(0, 2 * np.pi, len(key_features), endpoint=False).tolist()\n",
    "    feature_values += feature_values[:1]\n",
    "    angles += angles[:1]\n",
    "    \n",
    "    ax3.plot(angles, feature_values, 'o-', linewidth=2)\n",
    "    ax3.fill(angles, feature_values, alpha=0.25)\n",
    "    ax3.set_xticks(angles[:-1])\n",
    "    ax3.set_xticklabels(key_features)\n",
    "    ax3.set_title(\"Acoustic Feature Profile\", fontweight='bold')\n",
    "    ax3.grid(True)\n",
    "    \n",
    "    # 4. Time-domain features\n",
    "    ax4 = plt.subplot(3, 3, 4)\n",
    "    rms_time = librosa.frames_to_time(np.arange(len(rms)), sr=sr)\n",
    "    ax4.plot(rms_time, rms, 'g-', label='RMS Energy')\n",
    "    ax4.axhline(y=0.25, color='r', linestyle='--', label='Abnormal Threshold')\n",
    "    ax4.set_title(\"Energy Over Time\")\n",
    "    ax4.set_xlabel(\"Time (s)\")\n",
    "    ax4.set_ylabel(\"RMS\")\n",
    "    ax4.legend()\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 5. Frequency analysis\n",
    "    ax5 = plt.subplot(3, 3, 5)\n",
    "    fft = np.abs(np.fft.rfft(audio))\n",
    "    freqs = np.fft.rfftfreq(len(audio), 1/sr)\n",
    "    ax5.semilogy(freqs, fft, 'b-')\n",
    "    ax5.set_title(\"Frequency Spectrum\")\n",
    "    ax5.set_xlabel(\"Frequency (Hz)\")\n",
    "    ax5.set_ylabel(\"Magnitude\")\n",
    "    ax5.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 6. Detection result\n",
    "    ax6 = plt.subplot(3, 3, 6)\n",
    "    ax6.axis('off')\n",
    "    \n",
    "    is_abnormal = False\n",
    "    if result and 'is_abnormal' in result:\n",
    "        is_abnormal = result['is_abnormal']\n",
    "    \n",
    "    if is_abnormal:\n",
    "        ax6.text(0.5, 0.7, 'ðŸš¨ ABNORMAL SOUND', \n",
    "                fontsize=20, fontweight='bold', color='red',\n",
    "                ha='center', va='center')\n",
    "        if result and 'confidence' in result:\n",
    "            ax6.text(0.5, 0.5, f'Confidence: {result[\"confidence\"]:.1%}',\n",
    "                    fontsize=14, ha='center', va='center')\n",
    "        if result and 'class_probabilities' in result:\n",
    "            probs = result['class_probabilities']\n",
    "            top_class = max(probs.items(), key=lambda x: x[1])\n",
    "            ax6.text(0.5, 0.3, f'Type: {top_class[0]}',\n",
    "                    fontsize=14, ha='center', va='center')\n",
    "    else:\n",
    "        ax6.text(0.5, 0.7, 'âœ… NORMAL SOUND', \n",
    "                fontsize=20, fontweight='bold', color='green',\n",
    "                ha='center', va='center')\n",
    "    \n",
    "    # 7. Feature importance bars\n",
    "    ax7 = plt.subplot(3, 3, 7)\n",
    "    top_features = {\n",
    "        'Max RMS': features['max_rms'],\n",
    "        'Crest Factor': min(features['crest_factor'], 20),\n",
    "        'Zero-Crossing': features['max_zcr'],\n",
    "        'Spectral Centroid': features['centroid_mean'] / 1000,\n",
    "        'Impulse Ratio': features['impulse_ratio'] * 10\n",
    "    }\n",
    "    \n",
    "    colors = ['red' if is_abnormal else 'blue' for _ in top_features]\n",
    "    ax7.barh(list(top_features.keys()), list(top_features.values()), color=colors)\n",
    "    ax7.set_title(\"Key Feature Values\")\n",
    "    ax7.set_xlabel(\"Normalized Value\")\n",
    "    ax7.grid(True, alpha=0.3, axis='x')\n",
    "    \n",
    "    # 8. Onset detection\n",
    "    ax8 = plt.subplot(3, 3, 8)\n",
    "    onset_env = librosa.onset.onset_strength(y=audio, sr=sr)\n",
    "    onset_times = librosa.frames_to_time(np.arange(len(onset_env)), sr=sr)\n",
    "    ax8.plot(onset_times, onset_env, 'r-', label='Onset Strength')\n",
    "    ax8.set_title(\"Transient Detection\")\n",
    "    ax8.set_xlabel(\"Time (s)\")\n",
    "    ax8.set_ylabel(\"Onset Strength\")\n",
    "    ax8.legend()\n",
    "    ax8.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 9. Statistical distribution\n",
    "    ax9 = plt.subplot(3, 3, 9)\n",
    "    ax9.hist(audio, bins=50, alpha=0.7, density=True)\n",
    "    ax9.axvline(x=0, color='k', linestyle='--', alpha=0.5)\n",
    "    ax9.set_title(\"Amplitude Distribution\")\n",
    "    ax9.set_xlabel(\"Amplitude\")\n",
    "    ax9.set_ylabel(\"Density\")\n",
    "    ax9.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.suptitle(f\"Advanced Sound Analysis: {os.path.basename(audio_path)}\", \n",
    "                 fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# ============================================================================\n",
    "# 5. MAIN APPLICATION WITH GUI (OPTIONAL)\n",
    "# ============================================================================\n",
    "\n",
    "def main_menu():\n",
    "    \"\"\"Main menu for the enhanced detector\"\"\"\n",
    "    print(\"=\" * 70)\n",
    "    print(\"ENHANCED ABNORMAL SOUND DETECTION SYSTEM\")\n",
    "    print(\"=\" * 70)\n",
    "    print(\"Features:\")\n",
    "    print(\"  â€¢ Advanced feature extraction (50+ features)\")\n",
    "    print(\"  â€¢ Ensemble machine learning (4 models)\")\n",
    "    print(\"  â€¢ Adaptive thresholding\")\n",
    "    print(\"  â€¢ Real-time detection capability\")\n",
    "    print(\"  â€¢ Detailed visualization\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    detector = EnhancedAbnormalSoundDetector()\n",
    "    \n",
    "    while True:\n",
    "        print(\"\\nðŸ“‹ MAIN MENU:\")\n",
    "        print(\"  1. Quick test a sound file\")\n",
    "        print(\"  2. Train on custom dataset\")\n",
    "        print(\"  3. Real-time detection (microphone)\")\n",
    "        print(\"  4. Batch test directory\")\n",
    "        print(\"  5. Advanced visualization\")\n",
    "        print(\"  6. Save/Load model\")\n",
    "        print(\"  7. Exit\")\n",
    "        \n",
    "        choice = input(\"\\nSelect option (1-7): \").strip()\n",
    "        \n",
    "        if choice == '1':\n",
    "            file_path = input(\"Enter audio file path: \").strip().strip('\"\\'')\n",
    "            if os.path.exists(file_path):\n",
    "                result = detector.predict(file_path)\n",
    "                if result:\n",
    "                    print(f\"\\nðŸ” RESULT:\")\n",
    "                    if result['is_abnormal']:\n",
    "                        print(f\"  ðŸš¨ ABNORMAL SOUND DETECTED!\")\n",
    "                        print(f\"  Confidence: {result['confidence']:.1%}\")\n",
    "                        for cls, prob in sorted(result['class_probabilities'].items(), \n",
    "                                              key=lambda x: x[1], reverse=True)[:3]:\n",
    "                            print(f\"  {cls}: {prob:.1%}\")\n",
    "                    else:\n",
    "                        print(f\"  âœ… NORMAL SOUND\")\n",
    "                    \n",
    "                    # Show detailed visualization\n",
    "                    plot_choice = input(\"\\nShow detailed analysis? (y/n): \").lower()\n",
    "                    if plot_choice == 'y':\n",
    "                        plot_detailed_analysis(file_path, result)\n",
    "            else:\n",
    "                print(f\"âŒ File not found: {file_path}\")\n",
    "        \n",
    "        elif choice == '2':\n",
    "            print(\"\\nâš ï¸  Training requires labeled dataset.\")\n",
    "            print(\"Create folders: abnormal/, normal/, speech/, background/\")\n",
    "            print(\"Place audio files in respective folders.\")\n",
    "            \n",
    "            data_dir = input(\"\\nEnter dataset directory: \").strip()\n",
    "            if os.path.exists(data_dir):\n",
    "                # This would require actual dataset preparation\n",
    "                print(\"Dataset training would be implemented here...\")\n",
    "            else:\n",
    "                print(\"Directory not found.\")\n",
    "        \n",
    "        elif choice == '3':\n",
    "            print(\"\\nðŸŽ¤ Real-time detection starting...\")\n",
    "            rt_detector = RealTimeAbnormalDetector()\n",
    "            rt_detector.process_stream(None, duration=30)\n",
    "        \n",
    "        elif choice == '4':\n",
    "            test_dir = input(\"\\nEnter directory to test: \").strip()\n",
    "            if os.path.exists(test_dir):\n",
    "                import glob\n",
    "                audio_files = glob.glob(os.path.join(test_dir, \"*.wav\")) + \\\n",
    "                             glob.glob(os.path.join(test_dir, \"*.mp3\"))\n",
    "                \n",
    "                if audio_files:\n",
    "                    print(f\"\\nFound {len(audio_files)} files. Testing first 10...\")\n",
    "                    for i, file in enumerate(audio_files[:10]):\n",
    "                        print(f\"\\n[{i+1}/10] {os.path.basename(file)}\")\n",
    "                        result = detector.predict(file)\n",
    "                        if result:\n",
    "                            status = \"ðŸš¨ ABNORMAL\" if result['is_abnormal'] else \"âœ… NORMAL\"\n",
    "                            print(f\"  {status} (Confidence: {result['confidence']:.1%})\")\n",
    "        \n",
    "        elif choice == '5':\n",
    "            file_path = input(\"\\nEnter audio file for visualization: \").strip().strip('\"\\'')\n",
    "            if os.path.exists(file_path):\n",
    "                plot_detailed_analysis(file_path)\n",
    "            else:\n",
    "                print(\"File not found.\")\n",
    "        \n",
    "        elif choice == '6':\n",
    "            print(\"\\nðŸ’¾ Model Management:\")\n",
    "            print(\"  1. Save current model\")\n",
    "            print(\"  2. Load saved model\")\n",
    "            print(\"  3. Back to main menu\")\n",
    "            \n",
    "            sub_choice = input(\"Select (1-3): \").strip()\n",
    "            if sub_choice == '1':\n",
    "                detector.save_model()\n",
    "            elif sub_choice == '2':\n",
    "                detector.load_model()\n",
    "        \n",
    "        elif choice == '7':\n",
    "            print(\"\\nðŸ‘‹ Exiting...\")\n",
    "            break\n",
    "        \n",
    "        else:\n",
    "            print(\"âŒ Invalid choice. Please try again.\")\n",
    "\n",
    "# ============================================================================\n",
    "# SIMPLE COMMAND-LINE INTERFACE\n",
    "# ============================================================================\n",
    "\n",
    "def simple_cli():\n",
    "    \"\"\"Simple command-line interface\"\"\"\n",
    "    import sys\n",
    "    \n",
    "    if len(sys.argv) > 1:\n",
    "        file_path = sys.argv[1]\n",
    "    else:\n",
    "        file_path = input(\"Enter audio file path: \").strip().strip('\"\\'').strip()\n",
    "    \n",
    "    # Fix Windows path if needed\n",
    "    file_path = file_path.replace('\\\\', '/')\n",
    "    \n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"âŒ File not found: {file_path}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\nðŸ” Analyzing: {os.path.basename(file_path)}\")\n",
    "    \n",
    "    # Use enhanced detector\n",
    "    detector = EnhancedAbnormalSoundDetector()\n",
    "    \n",
    "    # Try to load pre-trained model\n",
    "    if not detector.load_model():\n",
    "        print(\"âš ï¸ Using rule-based detection (no trained model found)\")\n",
    "        # Fall back to quick detection\n",
    "        audio, sr = librosa.load(file_path, sr=16000, duration=3.0)\n",
    "        features = AdvancedAudioFeatures().extract_all_features(audio, sr)\n",
    "        \n",
    "        # Simple rule-based detection\n",
    "        is_abnormal = (\n",
    "            features['max_rms'] > 0.3 or\n",
    "            features['crest_factor'] > 8 or\n",
    "            features['max_zcr'] > 0.4 or\n",
    "            features['centroid_mean'] > 3500\n",
    "        )\n",
    "        \n",
    "        if is_abnormal:\n",
    "            if features['max_rms'] > 0.4 and features['crest_factor'] > 10:\n",
    "                sound_type = \"CAR CRASH / EXPLOSION\"\n",
    "            elif features['centroid_mean'] > 4000:\n",
    "                sound_type = \"GUNSHOT / GLASS\"\n",
    "            else:\n",
    "                sound_type = \"ABNORMAL SOUND\"\n",
    "            \n",
    "            print(f\"\\nðŸš¨ {sound_type} DETECTED!\")\n",
    "            print(f\"  Max Loudness: {features['max_rms']:.3f}\")\n",
    "            print(f\"  Crest Factor: {features['crest_factor']:.1f}\")\n",
    "            print(f\"  Frequency: {features['centroid_mean']:.0f} Hz\")\n",
    "        else:\n",
    "            print(f\"\\nâœ… NORMAL SOUND\")\n",
    "    else:\n",
    "        # Use ML model\n",
    "        result = detector.predict(file_path)\n",
    "        if result:\n",
    "            if result['is_abnormal']:\n",
    "                print(f\"\\nðŸš¨ ABNORMAL SOUND DETECTED!\")\n",
    "                print(f\"  Confidence: {result['confidence']:.1%}\")\n",
    "                \n",
    "                # Show top predictions\n",
    "                print(f\"\\nðŸ“Š Probability Breakdown:\")\n",
    "                for cls, prob in sorted(result['class_probabilities'].items(), \n",
    "                                      key=lambda x: x[1], reverse=True)[:3]:\n",
    "                    print(f\"  {cls}: {prob:.1%}\")\n",
    "            else:\n",
    "                print(f\"\\nâœ… NORMAL SOUND\")\n",
    "                print(f\"  Confidence: {result['confidence']:.1%}\")\n",
    "\n",
    "# ============================================================================\n",
    "# EXECUTION\n",
    "# ============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # For simple command-line usage\n",
    "    if len(sys.argv) > 1:\n",
    "        simple_cli()\n",
    "    else:\n",
    "        # For interactive mode\n",
    "        main_menu()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
